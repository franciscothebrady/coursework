# 2025-01-16

## Outline

1. Estimation
2. Precision
3. Hypothesis Testing
4. Statistical v. Substantive Significance

## Quantitative Estimates are the sum of three terms

Estimate = Estimand + Bias + Noise

- Estimate: The result
- Bias: Errors that occur for systematic reasons
- Noise: Idiosyncratic errors that occur based on chance 

NB: Even if you have bias, you may be able to learn something based on subject area knowledge. 

## Signing the bias

When there is negative bias:
--> estimate < estimand

Observed correlation (-) = True Causal Effect (-) + Bias (-) 
This will lead to:
The observed correlation being < True Causal Effect

If all three terms are negative, its hard to learn much from the correlation.

When there is positive bias:
Observed correlation (-) = True Causal Effect (-) + Bias (+) 
This will lead to:
The observed correlation being > True Causal Effect

In this case, we can still say that there is a causal effect because the bias moves in the direction against the true causal effect and we can still find a negative correlation. 

**Need to be sure that we know all of the likely biases to make an argument like this.

## Heterogeneity
If vaccines prevent the flu, should no one who gets the shot get the flu?

Assume there are 3 types of people:
1. always sick
2. never sick
3. vaccine responders

If there are any vaccine responders, then we say there is a causal effect.

## Can causality run backwards in time?

If A tends to precede B, can we say that A causes B
- Clive Granger -- [Granger causality test](https://phdinds-aim.github.io/time_series_handbook/04_GrangerCausality/04_GrangerCausality.html)

## Estimation

Again: Quantitative estimates are the sum of three terms

Estimate = Estimand + Bias + Noise

Example: Share of all voters who will vote republican
Create estimate $\hat{q}$:  
$\hat{q} = q + bias + noise$  

Estimator = the procedure you use to generate your estimate.  
Things that would lead to bias in this situation:
- sample error
- liars
- people who think they will vote but don't 

## Estimates differ from Estimands:

- Unbiased: if we repeat the procedure many time, the average *estimate* would be the **estimand**
- Precise: if we repeated our *estimator* many times, all the **estimates** would be close to each other.

## What determines precision of the estimate?
$$
Y_i = \gamma_0 + \gamma_1 T_i + u_i
$$

Recall that the standard error of $\hat{y}$ is: $\frac{Var[\hat{u}]}{(N - k - 1) \cdot Var[T_i]} $ 


