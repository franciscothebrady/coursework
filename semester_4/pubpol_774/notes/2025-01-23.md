## 2025-01-23

### Announcements

Problem set #1 this week (Friday)

### Recap

Estimates are the sum of 3 terms:

Estimate = Estimate + Bias + Noise

### Econometric Approach

Selection is the main source of bias

Goal is to address that by:
1. RCT
2. Regression Discontinuity
3. DiD
4. Instrumental Variables
5. Matching/Controlling for observables


### Practical Issues of Measurement

Elibimating bias and nosie isn't enough

- need to thinjk clearly about what you measure and how those quantities align with the **construct** you want to measure.

**Construct validity** - the degree to which a measurement tool accurately captures the theoretical concept is is intended to measure.

e.g. iThrive measures medical spending as a proxy for health.

### Gneezy et al 2019

PISA Test - worldwide study by OECD
- measures educational attainment by 15-year old students across the worl
- began in 2000, every 3 years
- comparable across countries

*Claims* to show problem-solving and cognition

- USA consistently underperforms, despite spending lots of money on education
    - why does US perform poorly?
    - socioeconomic factors, school systems, learning systems

### Test Scores

- why do we care about test scores?
    - We want to track how much students learn
    - education scores track with better outcomes
- what do we really want to know?

### Gneezy et all (2020)

- experiment to show students
    - put in less effort than students in hig performing countries (China)
    - would do better if more motivated

- randomly split students from US and Shanghai into two groups
    - control: test as normal
    - treatment: before the test surprise students with incentive to do well
        - surprise so they don't know about incentive in advance

Hypothesis:
1. US students don't put effort at baseline. when there is an incentive, they will try harder and improve.
2. chinese students are already trying hard when there is no incentive, so it won't make a difference in their performance.

### Design

- 25 minute test
- treatment: Receive $25 before test, $1 taken away for each incorrect question.

### Result

- large heterogeneity in US
- lower scoring US schools don't respond to incentives
- higher scoring US schools do respond to incentives
- schools in shanghai do not respond

### Conclusion

- success on low-stakes tests reflects not only ability, but also differences in motivations
- differences in effort can partially explain gaps across countries
    - may be relevant for other gaps such as race/ethnicity and SES

**Important to understand how your outcome is measured, and how that may affect interpretation of results**

### Issue #1: Bundled Outcomes

What is measured: student achievement + student effort + noise

- Gneezy, 2020 shows that it is hard to separate the two

**strategic adaptation**: efforts to improve outcomes lead people to adjust their behavior -- high stakes tests are meant to measure knowledge and comprehension and ability, but may just be measuring test-taking strategy.

### Issue #2: Timing

Choosing when to observe $Y_i$ might be very influential
- usually focused on estimating short-run substitution effects

the short run may differ from the long-run!

Example:
- pandora randomized ads per hour for listeners
- result: treatment effect grows over time --> increase ads decrease hours listened.
- elasticity depends on when they stop the experiment

Elasticity:
- if demand is inelastic, its revenue maximizing to increase ads
- if demand is elastic, its revenue maximizing to decrease ads

### Statistical Surrogates

Statistical surrogate is a measure that is more proximate and easily attainable than the measure you actually want (Prentice, 1989)
- Use short-run outcome and correlations from prior research to **extrapolate** the treatment effect of the outcome you actually care about.

### Extrapolating Surrogate Outcomes

1. The conditional distribution of the surrogate is the same in the observational and experimental samples.
2. Surrogates fully capture the causal link between the treatment and primary outcome.

#### Solutions:
- possible to use multiple surrogates for the same outcome
- combine outcomes into an index
- should make sure that surrogates are highly correlated with the outcome of interest

### Issue #3: Hypothetical v. revealed preferences

1. stated preferences -- survey measures a hypothetical outcome
2. consequential decisions -- look at changes in usage around the timing of privacy changes on a digital platform.
    - measuring actual behavior, not preferences

Why might stated and revealed preferences be different?
- bad memory
- don't always know their own preferences or motivations
- nothing guarantees answers are truthful
- people respond differently to hypothetical v. real questions

Athey, Catalini, Tucker (2017) asked students about their privacy preferences, then give them $100 in Bitcoin to analyze consequential privacy preferences.
- result: small incentives reduce revealed privacy concerns
- result: increased cost of privacy reduces privacy concerns

### Mismeasured Treatments

Burke, Hsiang, & Miguel (2015)
- estimate the effect of temperature fluctuations on GDP
- compare GDP growth within countries when exposed to warmer-than-average weather vs. colder-than-average temperatures.

Results:
- conclude that warming is expected to reduce average global incomes roughly 23% by 2100.
- authors interested in climate change, but the treatment measures temperature fluctuations.

### Conclusions
- estimates are a function of estimand, bias, and noise
- even if you can revocer a precise, unbiased, estimate, you still need to think clearly about what causal effdect you are measuring.

when you think this throuhg in data projects, consider common issues that arise for outcomes, treatments, and sample.