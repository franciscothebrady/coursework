## 2024-09-11

## Allow x_k to vary across it's range

We've used predicted probabilities so far, using Stata or R to predict the outcome for a hypothetical case.
Now we can allow $x_k$ to vary across its range, and see the effect on the outcome and then plot them.

```stata
margins, predict() at(lnGDPcap=(5(1)11) OilProdCap-.5 Landlock=0 Gini=25)
marginsplot
```
Note: if you leave the other variables empty they are set to the mean.

The basic plot is not very clean. so here is some code to make it look better.

```stata
marginsplot, legend(order(1 ”Not Free” 2 ”Partially Free” 3 ”Free”)) title(”Predicted Probilities Across Range of lnGDPcap”) noci
```

### Marginal Effect of OilProdCap

Given these other X values, what happens when you change the value of OilProdCap by a unit. 
i.e. the slope at that point, at what rate is the probability of a country being coded as "Not Free", "Partially Free", or "Free" will change.
```stata
margins, dydx(OilProdcap) at(lnGDPcap=9.21 OilProdcap=.5 Landlock=0 Gini=25)
```

In R, use the slopes function from that package.

### Average Marginal Effects
- In the above, we calculated the marginal effect of a one $x_k$ given specified value for the $x$'s.
Instead of looking at one hypothetical case, we're looking at the aggregate.
- With average marginal effects, we get the marginal effect on average across the entire sample

```stata
margins, dydx(OilProdcap) 
```

### Ordered Logit

- very much the same as ordered probit, except that the basic function is logistic
- stata command is ologit

### interpretation of ordered logit

- basically, everything is the same, except that we use the cumulative logistic distribution function instead of the normal distribution function
- the coefficients will be different, but the predicted probabilities and marginal effects will be the similar
- 

### Key Point
- when the dependent variable is ordinal, we estimate the probabilities with which a case falls into each category
- these probabilities sum to 1
- to estimate, we assume a latent dimension ($Y^*$) that is continuous with thresholds that divide it into regions associated with the ordinal categories
- each case is placed on this dimension. since there is uncertainty, there is some probability the case belongs in other categories
- we represent this uncertainty with a probability distribution and use it to estimate the probabilities of different outcomes

### Nominal-level Dependent variables

sometimes our outcome of interest is a set of categories that has no inherent order
- e.g. type of health insurance, choice of major

in these examples, we use our independent variables to predict the probability of each outcome for a particular case

### Example: School Choice
Asadullah and Maliki (2018) look at school choice in Indonesia
- three categories of schools: public, private, and madrasa
- in general madrasas are less expensive, and allow all genders.

### central question of interest
What factors lead households to send their children to madrasas?
some hypotheses:
1. madrasas attendance is driven by household poverty and cost-related factors
2. rural households are more likely to send their children to madrasas due to school quality
3. choice could be driven by religious factors

### data
- 82% in non-religious public schools, 11% in private non-relious schools, 3.8% in madrasas
- sample is ~190,000 households
- use many independent variables: child age, number of children, household size, household income, etc.

### results

two sets of estimates: one fro madrasa vs. private, madrasa vs. public
- public schools are the base category, and estimates are interpreted as relative to public schools

### Nominal (Unordered) Categories

- dependent variable is a discrete, finite set of categories with no inherent order
- the biggest change from ordered probit or logit is that we no longer assume a latent linear dimension
- the estimation technique is multinomial logit or probit

### some basic intuition

- we can think of multinomial logit as being similar to a set of binary lgits between each combination of categories.
- mathematically, it is just a more complicated likelihood function
- if y has j categories, we just estimate J - 1 sets of coefficients. One category serves as the base for comparison.
- relies a lot on the data, need lots of it, and makes this model somewhat fragile

### identifying the model
- we cannot estimate a set of coefficients for each of the j categories
- there would be an infinite number of solutions, just like there is no single x and y for which x * y = 4
- we thus set $\beta_j$ for one of the J categories to 0 for all k coefficients in the vector
- with one set of $\beta$'s fixed, the others have unique solutions.
- the choice is arbitrary

### the math: make category 1 the base category

$$
Pr(y = 1|x_i) = \frac{exp(x_i \beta_1)}{\sum_{j=1}^{J} exp(x_i \beta_j)}
$$

suppose however that category 1 is the vase category, (i.e. j = 1). set $\beta_1 = 0$

